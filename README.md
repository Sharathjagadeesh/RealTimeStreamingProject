
# Real-Time Stock Data Streaming Pipeline âŒ›ğŸ“ˆ

This project demonstrates a **real-time data streaming pipeline** using **Apache Beam (Python SDK)**, **Google Pub/Sub**, and **YFinance** to simulate stock market data from the **NSE (National Stock Exchange)**. The pipeline is designed to compute **percentage change** in stock prices over a **fixed time window of 5 and 10 minutes** using event-time windowing and stream processing.

---

## ğŸ“Œ Project Overview

- **Source**: YFinance API (mocked real-time using historical stock data).
- **Ingestion**: Google Cloud Pub/Sub.
- **Stream Processor**: Apache Beam with event-time and fixed windows.
- **Sink**: Console output (for simulation/demo purposes).
- **Cloud Ready**: Built for local execution, easily deployable on **Google Cloud Dataflow**.

---

## ğŸ› ï¸ Technologies Used

| Component            | Technology                    |
|---------------------|-------------------------------|
| Stream Ingestion     | Google Pub/Sub                 |
| Processing Engine    | Apache Beam (Python SDK)       |
| Data Source          | YFinance API                   |
| Cloud Environment    | Google Cloud Platform (GCP)    |

---

## ğŸ“‚ Project Structure

```
RealTimeStreamingProject/
â”‚
â”œâ”€â”€ pubsub_publisher.py              # Publishes stock data to Pub/Sub every 30s
â”œâ”€â”€ process_5min.py                  # Beam pipeline to process and window the stream
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ demo1-454518-XXXXXXX.json        # GCP service account credentials
â”œâ”€â”€ utils/                           # Any helper functions (optional)
â””â”€â”€ README.md                        # Project documentation
```

---

## ğŸ” Pipeline Flow

```
YFinance (Historical Data)
        â†“
publisher.py â†’ Publishes each stock row every 60s to Pub/Sub
        â†“
Google Cloud Pub/Sub Topic
        â†“
process_5min.py â†’ Apache Beam Pipeline:
    - Decode and parse rows
    - Extract necessary columns
    - Add event timestamp
    - Apply fixed window (5 minutes)
    - Group by stock symbol
    - Compute percentage price change
        â†“
    Output to console
	
process_10min.py â†’ Apache Beam Pipeline:
    - Decode and parse rows
    - Extract necessary columns
    - Add event timestamp
    - Apply fixed window (10 minutes)
    - Group by stock symbol
    - Compute percentage price change
        â†“
    Output to console
```

---

## ğŸ“ˆ Example Output

Every 5 minutes, Beam emits the source, percentage change, gain, first_open, last_closed, all_time_high, all_time_low in stock prices like:


Every 10 minutes, Beam emits the source, percentage change, gain, first_open, last_closed, all_time_high, all_time_low in stock prices like:

---

## ğŸ§  Key Concepts Covered

- â­ Apache Beam with event-time and fixed windowing
- â­ Google Pub/Sub integration with Beam
- â­ Real-time simulation using historical stock data
- â­ Percentage price change calculation
- â­ Grouping, sorting, and custom transforms in Beam
- â­ Streaming pipeline ready for GCP Dataflow

---

## ğŸ“¦ Installation & Setup

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/RealTimeStreamingProject.git
cd RealTimeStreamingProject
```

### 2. Create Virtual Environment & Install Dependencies

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Configure GCP Credentials

Ensure your **Google Cloud service account JSON** key is in the project directory.

```python
# Inside process_5min.py
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "demo1-454518-XXXXXXX.json"
```

### 4. Create Pub/Sub Topic & Subscription

Use Google Cloud Console or CLI:

```bash
gcloud pubsub topics create RealTimeStreamingProject
gcloud pubsub subscriptions create RealTimeStreamingProject-sub --topic=RealTimeStreamingProject
```

---

## â–¶ï¸ Run the Project Locally

### Step 1: Start the Publisher

```bash
python pubsub_publisher.py
```

This sends simulated stock data every 30 seconds to the Pub/Sub topic.

### Step 2: Start the Beam Pipeline

```bash
python process_5min.py
```

This starts a streaming pipeline that:
- Processes every message from the subscription
- Groups by stock every 5 minutes
- Calculates % price change
- Logs output

---

## ğŸ’¡ Real-World Use Cases

- ğŸ“Š Stock market monitoring
- ğŸ“‰ Real-time price fluctuation alerts (coming soon..!)
- ğŸ”„ Streaming ETL pipelines
- ğŸ§® Tumbling window analytics

---

## ğŸ™‹ Author

**Sharath**  
Data Engineer | Real-time Streaming Enthusiast  | ETL | Batch Processing
ğŸ“« [LinkedIn Profile]([https://linkedin.com/in/yourprofile](https://www.linkedin.com/in/sharath-j-503382219/))

---

**Explore my other projects**

- [Airflow Batch Processing project](https://github.com/Sharathjagadeesh/AirflowBatchProcessingProject.git)

---

---

**Thank you for reading!**

---
